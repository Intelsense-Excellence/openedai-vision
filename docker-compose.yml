services:
  server:
    build:
      context: .
      dockerfile: Dockerfile
    tty: true
    image: ghcr.io/matatonic/openedai-vision
    environment:
      - HF_HOME=/app/hf_home
    volumes:
      - ./hf_home:/app/hf_home
    ports:
      - 5006:5006
    #command: ["python", "vision.py", "--host", "0.0.0.0", "--port", "5006", "--backend", "llava", "--model", "llava-hf/llava-v1.6-mistral-7b-hf", "--load-in-4bit", "--use-flash-attn"]
    command: ["python", "vision.py", "--host", "0.0.0.0", "--port", "5006", "--use-flash-attn"]
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              #device_ids: ['0', '1'] # Select a gpu, or
              count: all
              capabilities: [gpu]
